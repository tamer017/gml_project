2025-01-25 22:06:02,226 saving log, checkpoint and back up code in folder: log
2025-01-25 22:06:02,226 ==========       args      =============
2025-01-25 22:06:02,226 phase:test
2025-01-25 22:06:02,227 exp_name:
2025-01-25 22:06:02,227 job_name:modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0
2025-01-25 22:06:02,227 use_cpu:False
2025-01-25 22:06:02,227 root_dir:log
2025-01-25 22:06:02,227 data_dir:Dataset
2025-01-25 22:06:02,227 dataset:ModelNet40
2025-01-25 22:06:02,227 num_points:2048
2025-01-25 22:06:02,227  :True
2025-01-25 22:06:02,227 in_channels:3
2025-01-25 22:06:02,227 batch_size:32
2025-01-25 22:06:02,227 epochs:400
2025-01-25 22:06:02,227 use_sgd:False
2025-01-25 22:06:02,227 weight_decay:0.0001
2025-01-25 22:06:02,227 lr:0.001
2025-01-25 22:06:02,227 seed:1
2025-01-25 22:06:02,227 multi_gpus:True
2025-01-25 22:06:02,227 test_batch_size:50
2025-01-25 22:06:02,227 pretrained_model:/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1-best_model.pth
2025-01-25 22:06:02,227 k:15
2025-01-25 22:06:02,227 block:dense
2025-01-25 22:06:02,227 conv:trans
2025-01-25 22:06:02,227 act:relu
2025-01-25 22:06:02,227 norm:batch
2025-01-25 22:06:02,227 bias:True
2025-01-25 22:06:02,227 n_blocks:7
2025-01-25 22:06:02,227 n_filters:256
2025-01-25 22:06:02,227 emb_dims:1024
2025-01-25 22:06:02,228 dropout:0.5
2025-01-25 22:06:02,228 dynamic:True
2025-01-25 22:06:02,228 fine_tune:False
2025-01-25 22:06:02,228 fine_tune_num_classes:16
2025-01-25 22:06:02,228 use_dilation:True
2025-01-25 22:06:02,228 epsilon:0.2
2025-01-25 22:06:02,228 use_stochastic:True
2025-01-25 22:06:02,228 device:cuda
2025-01-25 22:06:02,228 exp_dir:log
2025-01-25 22:06:02,228 res_dir:/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/result/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0
2025-01-25 22:06:02,228 loglevel:info
2025-01-25 22:06:02,228 ==========     args END    =============
2025-01-25 22:06:02,228 

2025-01-25 22:06:02,228 ===> Phase is test.
2025-01-25 22:06:02,233 ===> Creating data-loader ...
2025-01-25 22:06:05,797 ===> Loading ModelNet40 from Dataset. number of classes equal to 40
2025-01-25 22:06:05,797 ===> Loading the network ...
2025-01-25 22:06:06,129 ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
├─DynamicEdgeConvLayer: 1-1                        --
|    └─Sequential: 2-1                             --
|    |    └─Linear: 3-1                            1,792
|    |    └─ReLU: 3-2                              --
|    |    └─Linear: 3-3                            65,792
|    |    └─ReLU: 3-4                              --
|    └─DynamicEdgeConv: 2-2                        --
|    |    └─MaxAggregation: 3-5                    --
|    |    └─Sequential: 3-6                        (recursive)
|    └─BatchNorm1d: 2-3                            512
├─Sequential: 1-2                                  --
|    └─DenseDynBlock2d: 2-4                        --
|    |    └─DynConv2d: 3-7                         526,080
|    └─DenseDynBlock2d: 2-5                        --
|    |    └─DynConv2d: 3-8                         788,224
|    └─DenseDynBlock2d: 2-6                        --
|    |    └─DynConv2d: 3-9                         1,050,368
|    └─DenseDynBlock2d: 2-7                        --
|    |    └─DynConv2d: 3-10                        1,312,512
|    └─DenseDynBlock2d: 2-8                        --
|    |    └─DynConv2d: 3-11                        1,574,656
|    └─DenseDynBlock2d: 2-9                        --
|    |    └─DynConv2d: 3-12                        1,836,800
├─BasicConv: 1-3                                   --
|    └─Conv2d: 2-10                                7,340,032
|    └─LeakyReLU: 2-11                             --
|    └─BatchNorm2d: 2-12                           2,048
├─Sequential: 1-4                                  --
|    └─BasicConv: 2-13                             --
|    |    └─Conv2d: 3-13                           1,049,088
|    |    └─LeakyReLU: 3-14                        --
|    |    └─BatchNorm2d: 3-15                      1,024
|    |    └─Dropout2d: 3-16                        --
|    └─BasicConv: 2-14                             --
|    |    └─Conv2d: 3-17                           131,328
|    |    └─LeakyReLU: 3-18                        --
|    |    └─BatchNorm2d: 3-19                      512
|    |    └─Dropout2d: 3-20                        --
|    └─BasicConv: 2-15                             --
|    |    └─Conv2d: 3-21                           10,280
===========================================================================
Total params: 15,691,048
Trainable params: 15,691,048
Non-trainable params: 0
===========================================================================
2025-01-25 22:06:06,318 DataParallel(
  (module): DeepGCN(
    (dynamic_head): DynamicEdgeConvLayer(
      (mlp): Sequential(
        (0): Linear(in_features=6, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
      )
      (conv): DynamicEdgeConv(nn=Sequential(
        (0): Linear(in_features=6, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
      ), k=15)
      (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (backbone): Sequential(
      (0): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(256, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (1): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(512, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (2): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(768, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (3): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1024, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (4): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1280, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (5): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1536, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
    )
    (fusion_block): BasicConv(
      (0): Conv2d(7168, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (prediction): Sequential(
      (0): BasicConv(
        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2)
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): Dropout2d(p=0.5, inplace=False)
      )
      (1): BasicConv(
        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2)
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): Dropout2d(p=0.5, inplace=False)
      )
      (2): BasicConv(
        (0): Conv2d(256, 40, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
)
2025-01-25 22:06:06,321 ===> loading pre-trained ...
2025-01-25 22:06:06,322 ===> Loading checkpoint '/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1-best_model.pth'
2025-01-25 22:06:06,529 The pretrained_model is at checkpoint 167.
2025-01-25 22:06:27,461 Test Overall Acc 0.9214, Its test avg acc 0.8870.
2025-01-25 22:06:51,027 saving log, checkpoint and back up code in folder: log
2025-01-25 22:06:51,027 ==========       args      =============
2025-01-25 22:06:51,027 phase:test
2025-01-25 22:06:51,027 exp_name:
2025-01-25 22:06:51,027 job_name:modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0
2025-01-25 22:06:51,027 use_cpu:False
2025-01-25 22:06:51,027 root_dir:log
2025-01-25 22:06:51,027 data_dir:Dataset
2025-01-25 22:06:51,028 dataset:ModelNet40
2025-01-25 22:06:51,028 num_points:2048
2025-01-25 22:06:51,028  :True
2025-01-25 22:06:51,028 in_channels:3
2025-01-25 22:06:51,028 batch_size:32
2025-01-25 22:06:51,028 epochs:400
2025-01-25 22:06:51,028 use_sgd:False
2025-01-25 22:06:51,028 weight_decay:0.0001
2025-01-25 22:06:51,028 lr:0.001
2025-01-25 22:06:51,028 seed:1
2025-01-25 22:06:51,028 multi_gpus:True
2025-01-25 22:06:51,028 test_batch_size:50
2025-01-25 22:06:51,028 pretrained_model:/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1-best_model.pth
2025-01-25 22:06:51,028 k:15
2025-01-25 22:06:51,028 block:dense
2025-01-25 22:06:51,028 conv:trans
2025-01-25 22:06:51,028 act:relu
2025-01-25 22:06:51,028 norm:batch
2025-01-25 22:06:51,028 bias:True
2025-01-25 22:06:51,028 n_blocks:7
2025-01-25 22:06:51,028 n_filters:256
2025-01-25 22:06:51,028 emb_dims:1024
2025-01-25 22:06:51,028 dropout:0.5
2025-01-25 22:06:51,028 dynamic:True
2025-01-25 22:06:51,028 fine_tune:False
2025-01-25 22:06:51,028 fine_tune_num_classes:16
2025-01-25 22:06:51,028 use_dilation:True
2025-01-25 22:06:51,028 epsilon:0.2
2025-01-25 22:06:51,028 use_stochastic:True
2025-01-25 22:06:51,028 device:cuda
2025-01-25 22:06:51,028 exp_dir:log
2025-01-25 22:06:51,029 res_dir:/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/result/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0
2025-01-25 22:06:51,029 loglevel:info
2025-01-25 22:06:51,029 ==========     args END    =============
2025-01-25 22:06:51,029 

2025-01-25 22:06:51,029 ===> Phase is test.
2025-01-25 22:06:51,033 ===> Creating data-loader ...
2025-01-25 22:06:54,620 ===> Loading ModelNet40 from Dataset. number of classes equal to 40
2025-01-25 22:06:54,620 ===> Loading the network ...
2025-01-25 22:06:54,961 ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
├─DynamicEdgeConvLayer: 1-1                        --
|    └─Sequential: 2-1                             --
|    |    └─Linear: 3-1                            1,792
|    |    └─ReLU: 3-2                              --
|    |    └─Linear: 3-3                            65,792
|    |    └─ReLU: 3-4                              --
|    └─DynamicEdgeConv: 2-2                        --
|    |    └─MaxAggregation: 3-5                    --
|    |    └─Sequential: 3-6                        (recursive)
|    └─BatchNorm1d: 2-3                            512
├─Sequential: 1-2                                  --
|    └─DenseDynBlock2d: 2-4                        --
|    |    └─DynConv2d: 3-7                         526,080
|    └─DenseDynBlock2d: 2-5                        --
|    |    └─DynConv2d: 3-8                         788,224
|    └─DenseDynBlock2d: 2-6                        --
|    |    └─DynConv2d: 3-9                         1,050,368
|    └─DenseDynBlock2d: 2-7                        --
|    |    └─DynConv2d: 3-10                        1,312,512
|    └─DenseDynBlock2d: 2-8                        --
|    |    └─DynConv2d: 3-11                        1,574,656
|    └─DenseDynBlock2d: 2-9                        --
|    |    └─DynConv2d: 3-12                        1,836,800
├─BasicConv: 1-3                                   --
|    └─Conv2d: 2-10                                7,340,032
|    └─LeakyReLU: 2-11                             --
|    └─BatchNorm2d: 2-12                           2,048
├─Sequential: 1-4                                  --
|    └─BasicConv: 2-13                             --
|    |    └─Conv2d: 3-13                           1,049,088
|    |    └─LeakyReLU: 3-14                        --
|    |    └─BatchNorm2d: 3-15                      1,024
|    |    └─Dropout2d: 3-16                        --
|    └─BasicConv: 2-14                             --
|    |    └─Conv2d: 3-17                           131,328
|    |    └─LeakyReLU: 3-18                        --
|    |    └─BatchNorm2d: 3-19                      512
|    |    └─Dropout2d: 3-20                        --
|    └─BasicConv: 2-15                             --
|    |    └─Conv2d: 3-21                           10,280
===========================================================================
Total params: 15,691,048
Trainable params: 15,691,048
Non-trainable params: 0
===========================================================================
2025-01-25 22:06:55,147 DataParallel(
  (module): DeepGCN(
    (dynamic_head): DynamicEdgeConvLayer(
      (mlp): Sequential(
        (0): Linear(in_features=6, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
      )
      (conv): DynamicEdgeConv(nn=Sequential(
        (0): Linear(in_features=6, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
      ), k=15)
      (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (backbone): Sequential(
      (0): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(256, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (1): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(512, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (2): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(768, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (3): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1024, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (4): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1280, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (5): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1536, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
    )
    (fusion_block): BasicConv(
      (0): Conv2d(7168, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (prediction): Sequential(
      (0): BasicConv(
        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2)
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): Dropout2d(p=0.5, inplace=False)
      )
      (1): BasicConv(
        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2)
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): Dropout2d(p=0.5, inplace=False)
      )
      (2): BasicConv(
        (0): Conv2d(256, 40, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
)
2025-01-25 22:06:55,151 ===> loading pre-trained ...
2025-01-25 22:06:55,151 ===> Loading checkpoint '/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1-best_model.pth'
2025-01-25 22:06:55,346 The pretrained_model is at checkpoint 167.
2025-01-25 22:07:16,348 Test Overall Acc 0.9214, Its test avg acc 0.8870.
2025-01-25 22:09:22,624 saving log, checkpoint and back up code in folder: log
2025-01-25 22:09:22,624 ==========       args      =============
2025-01-25 22:09:22,624 phase:test
2025-01-25 22:09:22,624 exp_name:
2025-01-25 22:09:22,624 job_name:modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0
2025-01-25 22:09:22,624 use_cpu:False
2025-01-25 22:09:22,624 root_dir:log
2025-01-25 22:09:22,624 data_dir:Dataset
2025-01-25 22:09:22,624 dataset:ModelNet40
2025-01-25 22:09:22,624 num_points:2048
2025-01-25 22:09:22,625  :True
2025-01-25 22:09:22,625 in_channels:3
2025-01-25 22:09:22,625 batch_size:32
2025-01-25 22:09:22,625 epochs:400
2025-01-25 22:09:22,625 use_sgd:False
2025-01-25 22:09:22,625 weight_decay:0.0001
2025-01-25 22:09:22,625 lr:0.001
2025-01-25 22:09:22,625 seed:1
2025-01-25 22:09:22,625 multi_gpus:True
2025-01-25 22:09:22,625 test_batch_size:50
2025-01-25 22:09:22,625 pretrained_model:/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1-best_model.pth
2025-01-25 22:09:22,625 k:15
2025-01-25 22:09:22,625 block:dense
2025-01-25 22:09:22,625 conv:trans
2025-01-25 22:09:22,625 act:relu
2025-01-25 22:09:22,625 norm:batch
2025-01-25 22:09:22,625 bias:True
2025-01-25 22:09:22,625 n_blocks:7
2025-01-25 22:09:22,625 n_filters:256
2025-01-25 22:09:22,625 emb_dims:1024
2025-01-25 22:09:22,625 dropout:0.5
2025-01-25 22:09:22,625 dynamic:True
2025-01-25 22:09:22,625 fine_tune:False
2025-01-25 22:09:22,625 fine_tune_num_classes:16
2025-01-25 22:09:22,625 use_dilation:True
2025-01-25 22:09:22,625 epsilon:0.2
2025-01-25 22:09:22,625 use_stochastic:True
2025-01-25 22:09:22,625 device:cuda
2025-01-25 22:09:22,625 exp_dir:log
2025-01-25 22:09:22,625 res_dir:/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/result/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0
2025-01-25 22:09:22,625 loglevel:info
2025-01-25 22:09:22,625 ==========     args END    =============
2025-01-25 22:09:22,625 

2025-01-25 22:09:22,625 ===> Phase is test.
2025-01-25 22:09:22,630 ===> Creating data-loader ...
2025-01-25 22:09:26,173 ===> Loading ModelNet40 from Dataset. number of classes equal to 40
2025-01-25 22:09:26,173 ===> Loading the network ...
2025-01-25 22:09:26,520 ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
├─DynamicEdgeConvLayer: 1-1                        --
|    └─Sequential: 2-1                             --
|    |    └─Linear: 3-1                            1,792
|    |    └─ReLU: 3-2                              --
|    |    └─Linear: 3-3                            65,792
|    |    └─ReLU: 3-4                              --
|    └─DynamicEdgeConv: 2-2                        --
|    |    └─MaxAggregation: 3-5                    --
|    |    └─Sequential: 3-6                        (recursive)
|    └─BatchNorm1d: 2-3                            512
├─Sequential: 1-2                                  --
|    └─DenseDynBlock2d: 2-4                        --
|    |    └─DynConv2d: 3-7                         526,080
|    └─DenseDynBlock2d: 2-5                        --
|    |    └─DynConv2d: 3-8                         788,224
|    └─DenseDynBlock2d: 2-6                        --
|    |    └─DynConv2d: 3-9                         1,050,368
|    └─DenseDynBlock2d: 2-7                        --
|    |    └─DynConv2d: 3-10                        1,312,512
|    └─DenseDynBlock2d: 2-8                        --
|    |    └─DynConv2d: 3-11                        1,574,656
|    └─DenseDynBlock2d: 2-9                        --
|    |    └─DynConv2d: 3-12                        1,836,800
├─BasicConv: 1-3                                   --
|    └─Conv2d: 2-10                                7,340,032
|    └─LeakyReLU: 2-11                             --
|    └─BatchNorm2d: 2-12                           2,048
├─Sequential: 1-4                                  --
|    └─BasicConv: 2-13                             --
|    |    └─Conv2d: 3-13                           1,049,088
|    |    └─LeakyReLU: 3-14                        --
|    |    └─BatchNorm2d: 3-15                      1,024
|    |    └─Dropout2d: 3-16                        --
|    └─BasicConv: 2-14                             --
|    |    └─Conv2d: 3-17                           131,328
|    |    └─LeakyReLU: 3-18                        --
|    |    └─BatchNorm2d: 3-19                      512
|    |    └─Dropout2d: 3-20                        --
|    └─BasicConv: 2-15                             --
|    |    └─Conv2d: 3-21                           10,280
===========================================================================
Total params: 15,691,048
Trainable params: 15,691,048
Non-trainable params: 0
===========================================================================
2025-01-25 22:09:26,712 DataParallel(
  (module): DeepGCN(
    (dynamic_head): DynamicEdgeConvLayer(
      (mlp): Sequential(
        (0): Linear(in_features=6, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
      )
      (conv): DynamicEdgeConv(nn=Sequential(
        (0): Linear(in_features=6, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
      ), k=15)
      (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (backbone): Sequential(
      (0): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(256, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (1): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(512, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (2): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(768, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (3): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1024, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (4): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1280, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (5): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1536, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
    )
    (fusion_block): BasicConv(
      (0): Conv2d(7168, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (prediction): Sequential(
      (0): BasicConv(
        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2)
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): Dropout2d(p=0.5, inplace=False)
      )
      (1): BasicConv(
        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2)
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): Dropout2d(p=0.5, inplace=False)
      )
      (2): BasicConv(
        (0): Conv2d(256, 40, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
)
2025-01-25 22:09:26,715 ===> loading pre-trained ...
2025-01-25 22:09:26,716 ===> Loading checkpoint '/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1-best_model.pth'
2025-01-25 22:09:26,912 The pretrained_model is at checkpoint 167.
2025-01-25 22:09:47,867 Test Overall Acc 0.9214, Its test avg acc 0.8870.
2025-01-25 22:26:56,203 saving log, checkpoint and back up code in folder: log
2025-01-25 22:26:56,203 ==========       args      =============
2025-01-25 22:26:56,203 phase:test
2025-01-25 22:26:56,203 exp_name:
2025-01-25 22:26:56,203 job_name:modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0
2025-01-25 22:26:56,203 use_cpu:False
2025-01-25 22:26:56,203 root_dir:log
2025-01-25 22:26:56,203 data_dir:Dataset
2025-01-25 22:26:56,203 dataset:ModelNet40
2025-01-25 22:26:56,204 num_points:2048
2025-01-25 22:26:56,204  :True
2025-01-25 22:26:56,204 in_channels:3
2025-01-25 22:26:56,204 batch_size:32
2025-01-25 22:26:56,204 epochs:400
2025-01-25 22:26:56,204 use_sgd:False
2025-01-25 22:26:56,204 weight_decay:0.0001
2025-01-25 22:26:56,204 lr:0.001
2025-01-25 22:26:56,204 seed:1
2025-01-25 22:26:56,204 multi_gpus:True
2025-01-25 22:26:56,204 test_batch_size:50
2025-01-25 22:26:56,204 pretrained_model:/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1-best_model.pth
2025-01-25 22:26:56,204 k:15
2025-01-25 22:26:56,204 block:dense
2025-01-25 22:26:56,204 conv:trans
2025-01-25 22:26:56,204 act:relu
2025-01-25 22:26:56,204 norm:batch
2025-01-25 22:26:56,204 bias:True
2025-01-25 22:26:56,204 n_blocks:7
2025-01-25 22:26:56,204 n_filters:256
2025-01-25 22:26:56,204 emb_dims:1024
2025-01-25 22:26:56,204 dropout:0.5
2025-01-25 22:26:56,204 dynamic:True
2025-01-25 22:26:56,204 fine_tune:False
2025-01-25 22:26:56,204 fine_tune_num_classes:16
2025-01-25 22:26:56,204 use_dilation:True
2025-01-25 22:26:56,204 epsilon:0.2
2025-01-25 22:26:56,204 use_stochastic:True
2025-01-25 22:26:56,204 device:cuda
2025-01-25 22:26:56,204 exp_dir:log
2025-01-25 22:26:56,205 res_dir:/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/result/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0
2025-01-25 22:26:56,205 loglevel:info
2025-01-25 22:26:56,205 ==========     args END    =============
2025-01-25 22:26:56,205 

2025-01-25 22:26:56,205 ===> Phase is test.
2025-01-25 22:26:56,209 ===> Creating data-loader ...
2025-01-25 22:26:59,801 ===> Loading ModelNet40 from Dataset. number of classes equal to 40
2025-01-25 22:26:59,801 ===> Loading the network ...
2025-01-25 22:27:00,149 ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
├─DynamicEdgeConvLayer: 1-1                        --
|    └─Sequential: 2-1                             --
|    |    └─Linear: 3-1                            1,792
|    |    └─ReLU: 3-2                              --
|    |    └─Linear: 3-3                            65,792
|    |    └─ReLU: 3-4                              --
|    └─DynamicEdgeConv: 2-2                        --
|    |    └─MaxAggregation: 3-5                    --
|    |    └─Sequential: 3-6                        (recursive)
|    └─BatchNorm1d: 2-3                            512
├─Sequential: 1-2                                  --
|    └─DenseDynBlock2d: 2-4                        --
|    |    └─DynConv2d: 3-7                         526,080
|    └─DenseDynBlock2d: 2-5                        --
|    |    └─DynConv2d: 3-8                         788,224
|    └─DenseDynBlock2d: 2-6                        --
|    |    └─DynConv2d: 3-9                         1,050,368
|    └─DenseDynBlock2d: 2-7                        --
|    |    └─DynConv2d: 3-10                        1,312,512
|    └─DenseDynBlock2d: 2-8                        --
|    |    └─DynConv2d: 3-11                        1,574,656
|    └─DenseDynBlock2d: 2-9                        --
|    |    └─DynConv2d: 3-12                        1,836,800
├─BasicConv: 1-3                                   --
|    └─Conv2d: 2-10                                7,340,032
|    └─LeakyReLU: 2-11                             --
|    └─BatchNorm2d: 2-12                           2,048
├─Sequential: 1-4                                  --
|    └─BasicConv: 2-13                             --
|    |    └─Conv2d: 3-13                           1,049,088
|    |    └─LeakyReLU: 3-14                        --
|    |    └─BatchNorm2d: 3-15                      1,024
|    |    └─Dropout2d: 3-16                        --
|    └─BasicConv: 2-14                             --
|    |    └─Conv2d: 3-17                           131,328
|    |    └─LeakyReLU: 3-18                        --
|    |    └─BatchNorm2d: 3-19                      512
|    |    └─Dropout2d: 3-20                        --
|    └─BasicConv: 2-15                             --
|    |    └─Conv2d: 3-21                           10,280
===========================================================================
Total params: 15,691,048
Trainable params: 15,691,048
Non-trainable params: 0
===========================================================================
2025-01-25 22:27:00,331 DataParallel(
  (module): DeepGCN(
    (dynamic_head): DynamicEdgeConvLayer(
      (mlp): Sequential(
        (0): Linear(in_features=6, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
      )
      (conv): DynamicEdgeConv(nn=Sequential(
        (0): Linear(in_features=6, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
      ), k=15)
      (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (backbone): Sequential(
      (0): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(256, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (1): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(512, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (2): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(768, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (3): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1024, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (4): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1280, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (5): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1536, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
    )
    (fusion_block): BasicConv(
      (0): Conv2d(7168, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (prediction): Sequential(
      (0): BasicConv(
        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2)
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): Dropout2d(p=0.5, inplace=False)
      )
      (1): BasicConv(
        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2)
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): Dropout2d(p=0.5, inplace=False)
      )
      (2): BasicConv(
        (0): Conv2d(256, 40, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
)
2025-01-25 22:27:00,334 ===> loading pre-trained ...
2025-01-25 22:27:00,335 ===> Loading checkpoint '/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1-best_model.pth'
2025-01-25 22:27:00,528 The pretrained_model is at checkpoint 167.
2025-01-25 22:27:21,442 Test Overall Acc 0.9271, Its test avg acc 0.8933.
2025-01-25 22:28:34,045 saving log, checkpoint and back up code in folder: log
2025-01-25 22:28:34,045 ==========       args      =============
2025-01-25 22:28:34,045 phase:test
2025-01-25 22:28:34,045 exp_name:
2025-01-25 22:28:34,045 job_name:modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0
2025-01-25 22:28:34,045 use_cpu:False
2025-01-25 22:28:34,045 root_dir:log
2025-01-25 22:28:34,045 data_dir:Dataset
2025-01-25 22:28:34,045 dataset:ModelNet40
2025-01-25 22:28:34,045 num_points:2048
2025-01-25 22:28:34,045  :True
2025-01-25 22:28:34,045 in_channels:3
2025-01-25 22:28:34,045 batch_size:32
2025-01-25 22:28:34,045 epochs:400
2025-01-25 22:28:34,045 use_sgd:False
2025-01-25 22:28:34,045 weight_decay:0.0001
2025-01-25 22:28:34,045 lr:0.001
2025-01-25 22:28:34,045 seed:1
2025-01-25 22:28:34,045 multi_gpus:True
2025-01-25 22:28:34,045 test_batch_size:50
2025-01-25 22:28:34,045 pretrained_model:/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1-best_model.pth
2025-01-25 22:28:34,045 k:15
2025-01-25 22:28:34,045 block:dense
2025-01-25 22:28:34,045 conv:trans
2025-01-25 22:28:34,045 act:relu
2025-01-25 22:28:34,045 norm:batch
2025-01-25 22:28:34,045 bias:True
2025-01-25 22:28:34,045 n_blocks:7
2025-01-25 22:28:34,045 n_filters:256
2025-01-25 22:28:34,045 emb_dims:1024
2025-01-25 22:28:34,046 dropout:0.5
2025-01-25 22:28:34,046 dynamic:True
2025-01-25 22:28:34,046 fine_tune:False
2025-01-25 22:28:34,046 fine_tune_num_classes:16
2025-01-25 22:28:34,046 use_dilation:True
2025-01-25 22:28:34,046 epsilon:0.2
2025-01-25 22:28:34,046 use_stochastic:True
2025-01-25 22:28:34,046 device:cuda
2025-01-25 22:28:34,046 exp_dir:log
2025-01-25 22:28:34,046 res_dir:/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/result/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0
2025-01-25 22:28:34,046 loglevel:info
2025-01-25 22:28:34,046 ==========     args END    =============
2025-01-25 22:28:34,046 

2025-01-25 22:28:34,046 ===> Phase is test.
2025-01-25 22:28:34,050 ===> Creating data-loader ...
2025-01-25 22:28:37,608 ===> Loading ModelNet40 from Dataset. number of classes equal to 40
2025-01-25 22:28:37,609 ===> Loading the network ...
2025-01-25 22:28:37,936 ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
├─DynamicEdgeConvLayer: 1-1                        --
|    └─Sequential: 2-1                             --
|    |    └─Linear: 3-1                            1,792
|    |    └─ReLU: 3-2                              --
|    |    └─Linear: 3-3                            65,792
|    |    └─ReLU: 3-4                              --
|    └─DynamicEdgeConv: 2-2                        --
|    |    └─MaxAggregation: 3-5                    --
|    |    └─Sequential: 3-6                        (recursive)
|    └─BatchNorm1d: 2-3                            512
├─Sequential: 1-2                                  --
|    └─DenseDynBlock2d: 2-4                        --
|    |    └─DynConv2d: 3-7                         526,080
|    └─DenseDynBlock2d: 2-5                        --
|    |    └─DynConv2d: 3-8                         788,224
|    └─DenseDynBlock2d: 2-6                        --
|    |    └─DynConv2d: 3-9                         1,050,368
|    └─DenseDynBlock2d: 2-7                        --
|    |    └─DynConv2d: 3-10                        1,312,512
|    └─DenseDynBlock2d: 2-8                        --
|    |    └─DynConv2d: 3-11                        1,574,656
|    └─DenseDynBlock2d: 2-9                        --
|    |    └─DynConv2d: 3-12                        1,836,800
├─BasicConv: 1-3                                   --
|    └─Conv2d: 2-10                                7,340,032
|    └─LeakyReLU: 2-11                             --
|    └─BatchNorm2d: 2-12                           2,048
├─Sequential: 1-4                                  --
|    └─BasicConv: 2-13                             --
|    |    └─Conv2d: 3-13                           1,049,088
|    |    └─LeakyReLU: 3-14                        --
|    |    └─BatchNorm2d: 3-15                      1,024
|    |    └─Dropout2d: 3-16                        --
|    └─BasicConv: 2-14                             --
|    |    └─Conv2d: 3-17                           131,328
|    |    └─LeakyReLU: 3-18                        --
|    |    └─BatchNorm2d: 3-19                      512
|    |    └─Dropout2d: 3-20                        --
|    └─BasicConv: 2-15                             --
|    |    └─Conv2d: 3-21                           10,280
===========================================================================
Total params: 15,691,048
Trainable params: 15,691,048
Non-trainable params: 0
===========================================================================
2025-01-25 22:28:38,127 DataParallel(
  (module): DeepGCN(
    (dynamic_head): DynamicEdgeConvLayer(
      (mlp): Sequential(
        (0): Linear(in_features=6, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
      )
      (conv): DynamicEdgeConv(nn=Sequential(
        (0): Linear(in_features=6, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
      ), k=15)
      (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (backbone): Sequential(
      (0): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(256, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (1): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(512, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (2): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(768, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (3): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1024, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (4): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1280, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (5): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1536, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
    )
    (fusion_block): BasicConv(
      (0): Conv2d(7168, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (prediction): Sequential(
      (0): BasicConv(
        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2)
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): Dropout2d(p=0.5, inplace=False)
      )
      (1): BasicConv(
        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2)
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): Dropout2d(p=0.5, inplace=False)
      )
      (2): BasicConv(
        (0): Conv2d(256, 40, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
)
2025-01-25 22:28:38,130 ===> loading pre-trained ...
2025-01-25 22:28:38,131 ===> Loading checkpoint '/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1-best_model.pth'
2025-01-25 22:28:38,330 The pretrained_model is at checkpoint 167.
2025-01-25 22:28:59,045 Test Overall Acc 0.9271, Its test avg acc 0.8933.
2025-01-25 22:30:14,781 saving log, checkpoint and back up code in folder: log
2025-01-25 22:30:14,781 ==========       args      =============
2025-01-25 22:30:14,781 phase:test
2025-01-25 22:30:14,781 exp_name:
2025-01-25 22:30:14,781 job_name:modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0
2025-01-25 22:30:14,781 use_cpu:False
2025-01-25 22:30:14,781 root_dir:log
2025-01-25 22:30:14,781 data_dir:Dataset
2025-01-25 22:30:14,781 dataset:ModelNet40
2025-01-25 22:30:14,781 num_points:2048
2025-01-25 22:30:14,781  :True
2025-01-25 22:30:14,781 in_channels:3
2025-01-25 22:30:14,781 batch_size:32
2025-01-25 22:30:14,781 epochs:400
2025-01-25 22:30:14,781 use_sgd:False
2025-01-25 22:30:14,781 weight_decay:0.0001
2025-01-25 22:30:14,781 lr:0.001
2025-01-25 22:30:14,781 seed:1
2025-01-25 22:30:14,781 multi_gpus:True
2025-01-25 22:30:14,781 test_batch_size:50
2025-01-25 22:30:14,781 pretrained_model:/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1-best_model.pth
2025-01-25 22:30:14,782 k:15
2025-01-25 22:30:14,782 block:dense
2025-01-25 22:30:14,782 conv:trans
2025-01-25 22:30:14,782 act:relu
2025-01-25 22:30:14,782 norm:batch
2025-01-25 22:30:14,782 bias:True
2025-01-25 22:30:14,782 n_blocks:7
2025-01-25 22:30:14,782 n_filters:256
2025-01-25 22:30:14,782 emb_dims:1024
2025-01-25 22:30:14,782 dropout:0.5
2025-01-25 22:30:14,782 dynamic:True
2025-01-25 22:30:14,782 fine_tune:False
2025-01-25 22:30:14,782 fine_tune_num_classes:16
2025-01-25 22:30:14,782 use_dilation:True
2025-01-25 22:30:14,782 epsilon:0.2
2025-01-25 22:30:14,782 use_stochastic:True
2025-01-25 22:30:14,782 device:cuda
2025-01-25 22:30:14,782 exp_dir:log
2025-01-25 22:30:14,782 res_dir:/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/result/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0
2025-01-25 22:30:14,782 loglevel:info
2025-01-25 22:30:14,782 ==========     args END    =============
2025-01-25 22:30:14,782 

2025-01-25 22:30:14,782 ===> Phase is test.
2025-01-25 22:30:14,786 ===> Creating data-loader ...
2025-01-25 22:30:18,503 ===> Loading ModelNet40 from Dataset. number of classes equal to 40
2025-01-25 22:30:18,503 ===> Loading the network ...
2025-01-25 22:30:18,822 ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
├─DynamicEdgeConvLayer: 1-1                        --
|    └─Sequential: 2-1                             --
|    |    └─Linear: 3-1                            1,792
|    |    └─ReLU: 3-2                              --
|    |    └─Linear: 3-3                            65,792
|    |    └─ReLU: 3-4                              --
|    └─DynamicEdgeConv: 2-2                        --
|    |    └─MaxAggregation: 3-5                    --
|    |    └─Sequential: 3-6                        (recursive)
|    └─BatchNorm1d: 2-3                            512
├─Sequential: 1-2                                  --
|    └─DenseDynBlock2d: 2-4                        --
|    |    └─DynConv2d: 3-7                         526,080
|    └─DenseDynBlock2d: 2-5                        --
|    |    └─DynConv2d: 3-8                         788,224
|    └─DenseDynBlock2d: 2-6                        --
|    |    └─DynConv2d: 3-9                         1,050,368
|    └─DenseDynBlock2d: 2-7                        --
|    |    └─DynConv2d: 3-10                        1,312,512
|    └─DenseDynBlock2d: 2-8                        --
|    |    └─DynConv2d: 3-11                        1,574,656
|    └─DenseDynBlock2d: 2-9                        --
|    |    └─DynConv2d: 3-12                        1,836,800
├─BasicConv: 1-3                                   --
|    └─Conv2d: 2-10                                7,340,032
|    └─LeakyReLU: 2-11                             --
|    └─BatchNorm2d: 2-12                           2,048
├─Sequential: 1-4                                  --
|    └─BasicConv: 2-13                             --
|    |    └─Conv2d: 3-13                           1,049,088
|    |    └─LeakyReLU: 3-14                        --
|    |    └─BatchNorm2d: 3-15                      1,024
|    |    └─Dropout2d: 3-16                        --
|    └─BasicConv: 2-14                             --
|    |    └─Conv2d: 3-17                           131,328
|    |    └─LeakyReLU: 3-18                        --
|    |    └─BatchNorm2d: 3-19                      512
|    |    └─Dropout2d: 3-20                        --
|    └─BasicConv: 2-15                             --
|    |    └─Conv2d: 3-21                           10,280
===========================================================================
Total params: 15,691,048
Trainable params: 15,691,048
Non-trainable params: 0
===========================================================================
2025-01-25 22:30:19,008 DataParallel(
  (module): DeepGCN(
    (dynamic_head): DynamicEdgeConvLayer(
      (mlp): Sequential(
        (0): Linear(in_features=6, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
      )
      (conv): DynamicEdgeConv(nn=Sequential(
        (0): Linear(in_features=6, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
      ), k=15)
      (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (backbone): Sequential(
      (0): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(256, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (1): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(512, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (2): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(768, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (3): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1024, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (4): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1280, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
      (5): DenseDynBlock2d(
        (body): DynConv2d(
          (gconv): GraphTransformerLayer(
            (transformer): TransformerConv(1536, 64, heads=4)
            (feed_forward): Sequential(
              (0): Linear(in_features=256, out_features=512, bias=True)
              (1): ReLU()
              (2): Dropout(p=0.2, inplace=False)
              (3): Linear(in_features=512, out_features=256, bias=True)
            )
            (activation): ReLU()
          )
          (dilated_knn_graph): DenseDilatedKnnGraph(
            (_dilated): DenseDilated()
          )
        )
      )
    )
    (fusion_block): BasicConv(
      (0): Conv2d(7168, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): LeakyReLU(negative_slope=0.2)
      (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (prediction): Sequential(
      (0): BasicConv(
        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2)
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): Dropout2d(p=0.5, inplace=False)
      )
      (1): BasicConv(
        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (1): LeakyReLU(negative_slope=0.2)
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): Dropout2d(p=0.5, inplace=False)
      )
      (2): BasicConv(
        (0): Conv2d(256, 40, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
)
2025-01-25 22:30:19,011 ===> loading pre-trained ...
2025-01-25 22:30:19,012 ===> Loading checkpoint '/user/mahmoud.abdellahi/u12741/Project/deep_gcns_torch-master/examples/modelnet_cls/log/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1_20250104-172923_34882ee0-e264-45dc-9800-3c55c60552fb/checkpoint/modelnet_cls-dense-trans-n7-C256-norm_batch-k15-drop0.5-lr0.0001-B32-seed1-best_model.pth'
2025-01-25 22:30:19,200 The pretrained_model is at checkpoint 167.
2025-01-25 22:30:40,159 Test Overall Acc 0.9271, Its test avg acc 0.8933.
